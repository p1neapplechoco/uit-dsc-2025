{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899f851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T04:07:54.626617Z",
     "iopub.status.busy": "2025-09-26T04:07:54.626040Z",
     "iopub.status.idle": "2025-09-26T04:07:54.630590Z",
     "shell.execute_reply": "2025-09-26T04:07:54.629708Z",
     "shell.execute_reply.started": "2025-09-26T04:07:54.626593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "DATA_DIR = Path(\"/kaggle/input/ts-pmo/vihallu-train_part_1.csv\")\n",
    "OUTPUT_DIR = Path(\"vihallu-train-corrected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e550a-2568-408f-b970-0d23ef2abe65",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62899b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T04:06:49.199624Z",
     "iopub.status.busy": "2025-09-26T04:06:49.199011Z",
     "iopub.status.idle": "2025-09-26T04:06:49.206183Z",
     "shell.execute_reply": "2025-09-26T04:06:49.205499Z",
     "shell.execute_reply.started": "2025-09-26T04:06:49.199602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def correct_prompt(context, prompt, response, model, tokenizer):\n",
    "    sys_prompt = (\n",
    "        \"Bạn là một bộ sửa chính tả tiếng Việt. \"\n",
    "        \"Chỉ sửa lỗi CHÍNH TẢ/đánh máy và thêm dấu cho các từ ngữ trong PROMPT, có thể dùng CONTEXT/RESPONSE để đoán chữ đúng. \"\n",
    "        \"KHÔNG thêm ý mới, KHÔNG đổi nội dung nghĩa, KHÔNG liệt kê hay giải thích. \"\n",
    "        \"Nếu không cần sửa thì trả về nguyên văn PROMPT. \"\n",
    "        \"Chỉ trả về MỘT DÒNG là câu PROMPT đã được sửa, không thêm dấu ngoặc hay tiền tố nào.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"CONTEXT:\\n{context}\\n\\n\"\n",
    "        f\"PROMPT:\\n{prompt}\\n\\n\"\n",
    "        f\"RESPONSE:\\n{response}\\n\"\n",
    "        \"Yêu cầu: Trả về đúng MỘT câu PROMPT đã được sửa lỗi chính tả.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True,\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = (\n",
    "        (inputs != tokenizer.pad_token_id).long()\n",
    "        if tokenizer.pad_token_id is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            inputs,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            top_p=0.7,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.0,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    new_tokens = generation_output[0, inputs.shape[-1]:]\n",
    "    text = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "    # print(\"Corrected Prompt:\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61358f-cb8c-442a-b66e-748115e8aa3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T04:07:59.369136Z",
     "iopub.status.busy": "2025-09-26T04:07:59.368773Z",
     "iopub.status.idle": "2025-09-26T04:07:59.651602Z",
     "shell.execute_reply": "2025-09-26T04:07:59.651035Z",
     "shell.execute_reply.started": "2025-09-26T04:07:59.369115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "\n",
    "def get_item_by_id(data, id) -> dict:\n",
    "    item = data[data['id'] == id].iloc[0]\n",
    "\n",
    "    return {\n",
    "        'context': item['context'],\n",
    "        'prompt': item['prompt'],\n",
    "        'response': item['response']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811b78b-5ed6-4519-931d-a2ac6a3ed1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T04:08:02.527174Z",
     "iopub.status.busy": "2025-09-26T04:08:02.526895Z",
     "iopub.status.idle": "2025-09-26T04:08:08.843363Z",
     "shell.execute_reply": "2025-09-26T04:08:08.842714Z",
     "shell.execute_reply.started": "2025-09-26T04:08:02.527155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    corrected = correct_prompt(\n",
    "        row[\"context\"], row[\"prompt\"], row[\"response\"], model, tokenizer\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"context\": row[\"context\"],\n",
    "            \"prompt\": row[\"prompt\"],\n",
    "            \"corrected_prompt\": corrected,\n",
    "            \"response\": row[\"response\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e4009-307a-4b01-b3bd-ef24dac69bd3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(OUTPUT_DIR, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8318929,
     "sourceId": 13131696,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8330826,
     "sourceId": 13174850,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
